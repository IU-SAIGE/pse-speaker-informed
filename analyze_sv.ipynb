{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "import os\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import cm\n",
    "from scipy.io import wavfile\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import _datasets as D\n",
    "import _models as M\n",
    "\n",
    "EPS = 1e-8\n",
    "\n",
    "# select device\n",
    "device = 'cpu'\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "\n",
    "def reverse_non_unique_mapping(d):\n",
    "    dinv = {}\n",
    "    for k, v in d.items():\n",
    "        k = str(k)\n",
    "        v = int(v)\n",
    "        if v in dinv:\n",
    "            dinv[v].append(k)\n",
    "        else:\n",
    "            dinv[v] = [k]\n",
    "    return dinv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate speaker-mean vectors per checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished!\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = 'weights/sv'\n",
    "\n",
    "if os.path.exists(checkpoint_path):\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        with open(checkpoint_path + '_params.json', 'r') as fp:\n",
    "            checkpoint_params = json.load(fp)\n",
    "        hidden_size = int(checkpoint_params['hidden_size'])\n",
    "\n",
    "        # instantiate network\n",
    "        network = M.NetSV(hidden_size=hidden_size, num_layers=2).to(device)\n",
    "        sd = torch.load(checkpoint_path, map_location=torch.device(device))\n",
    "        network.load_state_dict(sd)\n",
    "\n",
    "        # loop through each speaker\n",
    "        mean_vectors = {}\n",
    "        for speaker_id in D.speaker_ids_tr:\n",
    "            df = D.librispeech.query(f'speaker_id == \"{speaker_id}\"')\n",
    "            vectors = []\n",
    "            for filepath in df.filepath:\n",
    "                (_, s) = wavfile.read(filepath)\n",
    "                s = s / np.abs(s).max()\n",
    "                s = torch.Tensor(s).unsqueeze(0).to(device)\n",
    "                features = network.embedding(s).squeeze()\n",
    "                vectors.append(features)\n",
    "            vectors = torch.stack(vectors)\n",
    "            mean_vectors[speaker_id] = torch.mean(vectors, dim=0).cpu().numpy()\n",
    "\n",
    "        np.save(checkpoint_path + '_speakers.npy', mean_vectors)\n",
    "        print('Finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Do k-means clustering on the speaker vectors, use TSNE for visualization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [],
   "source": [
    "figsize = (4, 2)\n",
    "dpi = 300\n",
    "seed = 0\n",
    "plot = False\n",
    "save_mapping_to_file = True\n",
    "\n",
    "plt.style.use(['science', 'ieee'])\n",
    "\n",
    "df = mean_vectors\n",
    "data = np.vstack(list(df.values()))\n",
    "labels = np.vstack(list(df.keys())).squeeze()\n",
    "\n",
    "import yaml\n",
    "\n",
    "for num_clusters in [2, 3, 4, 5, 6, 7, 8, 9, 10]:\n",
    "\n",
    "    kmeans = KMeans(n_clusters=num_clusters, random_state=seed).fit(data)\n",
    "    classes = kmeans.labels_\n",
    "    mapping_1 = {str(k): int(v) for (k,v) in zip(labels, classes)}\n",
    "    mapping_2 = reverse_non_unique_mapping(mapping_1)\n",
    "    \n",
    "    if save_mapping_to_file:\n",
    "        with open(checkpoint_path+f'_mapping_k={num_clusters:02d}.yaml', 'w') as fp:\n",
    "            yaml.dump({'speakers': mapping_1, 'specialists': mapping_2}, fp)\n",
    "    \n",
    "    if not plot:\n",
    "        continue\n",
    "\n",
    "    tsne = TSNE(n_components=2, verbose=0, perplexity=40, n_iter=300, random_state=seed)\n",
    "    data_2d = tsne.fit_transform(data)\n",
    "\n",
    "    fig = plt.figure(figsize=figsize, dpi=dpi)\n",
    "    plt.xlabel(r'1\\textsuperscript{st} Dimension')\n",
    "    plt.ylabel(r'2\\textsuperscript{nd} Dimension')\n",
    "\n",
    "    # plot by k-means\n",
    "    for i in range(0, len(labels), 1):\n",
    "        colors = cm.get_cmap('tab10').colors\n",
    "        gender = D.speakers_tr[D.speakers_tr.speaker_id==labels[i]].gender.item()\n",
    "        plt.scatter(data_2d[i, 0], data_2d[i, 1], color=colors[classes[i]], s=32,\n",
    "                    linewidths=0.2, edgecolors='k', marker={'M': 'P', 'F': 'D'}[gender])\n",
    "\n",
    "    hd_gender = [\n",
    "        plt.plot((-100,), (-100,), ls='none', marker='P', markersize=6, c='k',\n",
    "                        label='Male')[0],\n",
    "        plt.plot((-100,), (-100,), ls='none', marker='D', markersize=4.5, c='k',\n",
    "                        label='Female')[0]\n",
    "    ]\n",
    "    hd_cluster = [\n",
    "        plt.plot((-100,), (-100,), ls='none', marker='o', mec='k', \n",
    "                 markeredgewidth=0.5,\n",
    "                 color=colors[i],\n",
    "                 label=(f'{i+1}'))[0]\n",
    "        for i in range(0, len(set(classes)))\n",
    "    ]\n",
    "    plt.gca().add_artist(plt.legend(handles=hd_gender, ncol=2, columnspacing=1,\n",
    "                                    handletextpad=0.2, fontsize=8, loc='lower right'))\n",
    "    plt.gca().add_artist(plt.legend(handles=hd_cluster, ncol=3, columnspacing=1,\n",
    "                                    handletextpad=0, fontsize=8, loc='upper left'))\n",
    "    plt.xlim([-15, 15])\n",
    "    plt.ylim([-15, 15])\n",
    "\n",
    "    plt.savefig(f'figures/fig_tsne-k{num_clusters:02d}.pdf',\n",
    "                facecolor='white', transparent=False, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
